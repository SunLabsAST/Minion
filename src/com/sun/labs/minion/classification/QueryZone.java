/*
 * Copyright 2007-2008 Sun Microsystems, Inc. All Rights Reserved.
 * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER
 * 
 * This code is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License version 2
 * only, as published by the Free Software Foundation.
 * 
 * This code is distributed in the hope that it will be useful, but
 * WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
 * General Public License version 2 for more details (a copy is
 * included in the LICENSE file that accompanied this code).
 * 
 * You should have received a copy of the GNU General Public License
 * version 2 along with this work; if not, write to the Free Software
 * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
 * 02110-1301 USA
 * 
 * Please contact Sun Microsystems, Inc., 16 Network Circle, Menlo
 * Park, CA 94025 or visit www.sun.com if you need additional
 * information or have any questions.
 */

package com.sun.labs.minion.classification;

import java.util.ArrayList;
import java.util.Iterator;
import java.util.List;
import java.util.PriorityQueue;

import com.sun.labs.minion.indexer.partition.DiskPartition;
import com.sun.labs.minion.indexer.partition.PartitionManager;

import com.sun.labs.minion.retrieval.ArrayGroup;
import com.sun.labs.minion.retrieval.ResultSetImpl;
import com.sun.labs.minion.retrieval.cache.TermCache;
import com.sun.labs.minion.retrieval.TermStatsImpl;
import com.sun.labs.minion.retrieval.WeightingComponents;
import com.sun.labs.minion.retrieval.WeightingFunction;
import java.util.Map;

/**
 * A query zone is a set of documents that are centered around a set
 * of feature clusters.  The features in the clusters are organized into
 * a big query, and results are returned in score order.  The results
 * will contain a mix of documents in and out of the training set.
 *
 */
public class QueryZone {

    /**
     * The field we're building classifiers from.
     */
    protected String fromField;
    
    /**
     * A term cache to use when building classifiers.
     */
    protected Map<DiskPartition,TermCache> termCaches;

    /**
     * The features that we will use for our model.
     */
    protected FeatureClusterSet wfClusters;

    /** 
     * The partition manager for the documents in the collection 
     */
    protected PartitionManager manager;

    /** 
     * The training set for the class under construction 
     */
    protected ResultSetImpl training;

    /** 
     * The weighting function to use 
     */
    protected WeightingFunction wf;

    /** 
     * The weighting components to use 
     */
    protected WeightingComponents wc;

    /** 
     * The contents of the query zone 
     */
    protected PriorityQueue<HE> h;

    /** 
     * A list of all the heap elements 
     */
    protected List<HE> heapElements;

    public QueryZone(ResultSetImpl training,
            String fromField,
            FeatureClusterSet featureClusters,
            Map<String,TermStatsImpl> termStats,
            Map<DiskPartition,TermCache> termCaches,
            PartitionManager manager) {
        this.termCaches = termCaches;
        this.training = training;
        this.fromField = fromField;
        
        //
        // We'll need a weighting function and a set of weighting
        // components for a lot of stuff.
        wf = manager.getQueryConfig().getWeightingFunction();
        wc = manager.getQueryConfig().getWeightingComponents();

        //
        // Now, the features that were selected have weights generated by
        // the computation in the feature selector.  We need a set of
        // features that have weights generated from the term weights in
        // the collection.  We'll calculate those now.
        wfClusters = new FeatureClusterSet();

        for(Iterator i = featureClusters.iterator(); i.hasNext();) {

            //
            // Get the feature cluster.
            FeatureCluster c = (FeatureCluster) i.next();
            TermStatsImpl ts = termStats.get(c.getName());

            //
            // Copy the current cluster and set its weight to the weight we
            // just calculated.
            FeatureCluster cwf = c.copy();
            cwf.setWeight(wf.initTerm(wc.setTerm(ts)));
            wfClusters.add(cwf);
        }

    }

    public PriorityQueue<HE> computeZone() {
        //
        // We want to normalize the features in our set of weighted feature
        // clusters so that we don't have to keep normalizing everything.
        wfClusters.normalize();

        //
        // We're going to iterate through the training set partition by
        // partition, since that will allow us to do the maximal number of
        // things using integer IDs, rather than strings.
        //
        // For each partition, we'll build a big query from all of the
        // features that were selected.  The big query will be doing
        // lookups of all the terms in all of the feature clusters, and
        // we'll cache the integer IDs for those terms so that later we can
        // match them against the terms that we find in documents in the
        // result set that we'll build from the big query.
        //
        // The results of the big query will be the basis for a heap of big
        // queries from each partition.  We'll build that heap now.
        h = new PriorityQueue<HE>();
        heapElements = new ArrayList<HE>();
        for(Iterator i = training.resultsIterator(); i.hasNext();) {
            ArrayGroup tg = (ArrayGroup) i.next();
            BigQuery bq = new BigQuery(termCaches.get(tg.getPartition()), tg, fromField, wf, wc);

            //
            // Add all of our selected features to the query.  Note that
            // we're using the features that have collection derived
            // weights, not feature selection derived weights!
            bq.addFeatureClusters(wfClusters);

            //
            // Make an element for our heap out of this big query, and
            // remember the element in a list.
            HE el = new HE(bq, wf, wc);
            if(el.next()) {
                heapElements.add(el);
                h.offer(el);
            }
        }
        return h;
    }

    /** 
     * Gets a heap that represents the members of the query zone.  Each
     * element of the heap contains a big query and an array group that
     * represent all the results from a partition.  The heap elements
     * provide method to facilitate access to the current/top document
     * from the partition that the element represents.
     * 
     * @return the heap of all documents in the query zone
     */
    public PriorityQueue<HE> getHeap() {
        return h;
    }

    /** 
     * Returns the feature clusters used to determine this query zone
     * with collection level weights assigned to them.  Note that once
     * computeZone is called, the feature clusters returned will be
     * normalized.  Before computeZone is called they are not.  A copy
     * of the feature clusters should be made if the clusters will be
     * modified.
     * 
     * @return the internal set of feature clusters
     */
    public FeatureClusterSet getWeightedClusters() {
        return wfClusters;
    }

    class HE implements Comparable<HE> {

        public BigQuery bq;

        public WeightingFunction wf;

        public WeightingComponents wc;

        public ArrayGroup.DocIterator iter;

        public WeightedFeatureVector pos;

        public WeightedFeatureVector neg;

        /**
         * Creates an element for the heap for a given array group.
         *
         * @param bq the query for which we're building centroids
         */
        public HE(BigQuery bq, WeightingFunction wf, WeightingComponents wc) {
            this.bq = bq;
            this.wf = wf;
            this.wc = wc;
            iter = bq.getGroup().iterator();
        }

        /**
         * Advances our iterator, returning true if there is a next
         * element. 
         */
        public boolean next() {
            return iter.next();
        }

        /** 
         * Gets the document ID that the iterator is currently
         * pointing at.
         * 
         * @return a doc ID
         */
        public int getDoc() {
            return iter.getDoc();
        }

        /** 
         * Get the partition that this element is associated with
         * 
         * @return the partition
         */
        public DiskPartition getPartition() {
            return bq.part;
        }

        /** 
         * Removes the given id from the set of training IDs if the
         * the set of training IDs contained the given id.
         * 
         * @param id the id to remove
         * @return true if the training set contained the id
         */
        public boolean removeFromTraining(int id) {
            return bq.trainingIDs.remove(id);
        }

        /**
         * Returns an iterator over any remaining training documents.
         */
        public Iterator getRemainingTraining() {
            return bq.trainingIDs.iterator();
        }

        /**
         * Our comparison will be based on the iterators.
         */
        public int compareTo(HE o) {
            return -iter.compareTo(o.iter);
        }
    }
}
