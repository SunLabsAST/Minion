/*
 * Copyright 2007-2008 Sun Microsystems, Inc. All Rights Reserved.
 * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER
 * 
 * This code is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License version 2
 * only, as published by the Free Software Foundation.
 * 
 * This code is distributed in the hope that it will be useful, but
 * WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
 * General Public License version 2 for more details (a copy is
 * included in the LICENSE file that accompanied this code).
 * 
 * You should have received a copy of the GNU General Public License
 * version 2 along with this work; if not, write to the Free Software
 * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
 * 02110-1301 USA
 * 
 * Please contact Sun Microsystems, Inc., 16 Network Circle, Menlo
 * Park, CA 94025 or visit www.sun.com if you need additional
 * information or have any questions.
 */
package com.sun.labs.minion.document.tokenizer;

import com.sun.labs.minion.pipeline.Stage;
import com.sun.labs.minion.pipeline.Token;

import com.sun.labs.minion.util.Util;
import java.util.Arrays;
import java.util.logging.Logger;

/**
 * A class for tokenizing text in any language and mixed language material.
 *
 * This particular subclass is meant for special use in synchronous pipelines,
 * where all stages are running in the same thread.  This leads to a lot of
 * (almost total) code duplication between tokenizers, but there doesn't
 * appear to be a clean way to do it without having a conditional statement
 * for each token we want to add.
 *
 * This tokenizer uses bigram tokenization, whenever it encounters characters
 * in the CJK range (Chinese, Japanese, and Korean), and otherwise tokenizes
 * using punctuation and whitespace separators to separate words.  Within runs
 * of CJK characters, the tokenizer will ignore end-of-lines etc. and not
 * treat them as white space, and it will generate sequences of overlapping
 * ngrams of length one and two for every character and every character pair
 * in the sequence.  At the beginning of such a sequence, it will generate
 * a null+char transition pair and at the end it will generate a char+null
 * transition pair.  For example, a sequence of three Chinese characters,
 * XYZ, would tokenize as 0X, X, XY, Y, YZ, Z, Z0, representing the fact
 * that the sequence starts with X, ends with Z, and contains the other
 * listed characters and pairs in the listed order.  In reporting beginning
 * and ending positions for these tokens, the single character tokens begin
 * at the position of the character and end one position later, while the
 * bigram (pair) tokens have zero length, beginning and ending at the position
 * of their second character (i.e., the point in between the two characters).
 *
 * This tokenizer also has provisions for running in either a smart or
 * simple mode, depending on the setting of the static final flag simpleFlag.
 * When simpleFlag is true, any punctuation characters will cause word breaks
 * and if sendPunct is true will generate punctuation tokens.  When simpleFlag
 * is false, the tokenizer will use specialized knowledge to tokenize as whole
 * words many common notations that include some punctuation marks, such as:
 * "3:00", "http://www.sun.com", "william.woods@sun.com", "A&P", "U.S.",
 * "5/15/02", "1,024", "3.1415", etc.
 *
 * There are also provisions for tracing the behavior, when the static final
 * bookean authorFlag is true.  This is useful when making modifications to
 * the tokenization logic, or for understanding the behavior of the tokenizer
 * in detail.  When authorFlag is true, the public variable traceFlag can be
 * used to turn tracing on and off.
 *
 * Note that the tokens generated by the tokenizer use beginning and ending
 * position conventions similar to substrings in a string, by specifying
 * the position of the first character in the token and the character position
 * just beyond the last character of the token.  This is different from the
 * current convention for the pipeline events that the tokenizer handles, in
 * which the ending convention is to specify the character position of the
 * last character of the event. (?? Should this convention be changed?)
 */
public class UniversalTokenizer extends Tokenizer {

    public UniversalTokenizer() {
        this(null);
    }

    /**
     * Create a tokenizer that will send its output to the given
     * <code>Stage</code>.
     * @param s the stage to which the output of the tokenizer will be sent.
     */
    public UniversalTokenizer(Stage s) {
        super(s);
        token = new char[32];
        tokLen = 0;
        lengths = new int[32];
        state = INITIAL;
        breakCharFlag = false;
        makeTokens = true;

        // pc is null char to start, otherwise pc carries across handleText
        // and handleEvent.
        pc = 0;
        pcl = 0;
        ngramLength = 2;
        nullString = new char[ngramLength];
        for(int i = 0; i < ngramLength; i++) {
            nullString[i] = (char) 0;
        }
    }

    /**
     * Create a tokenizer that will send its output to the given
     * <code>Stage</code> and generate tokens for punctuation
     * if boolean sp (for "sendPunct") is true.
     * @param s The output stage to receive the generated tokens.
     * @param sp Flag indicating whether to transmit punctuation.
     */
    public UniversalTokenizer(Stage s, boolean sp) {
        super(s, sp);
        token = new char[32];
        tokLen = 0;
        lengths = new int[32];
        state = INITIAL;
        breakCharFlag = false;
        makeTokens = true;

        // pc is null char to start, otherwise pc carries across handleText
        // and handleEvent.
        pc = 0;
        pcl = 0;
        ngramLength = 2;
        nullString = new char[ngramLength];
        for(int i = 0; i < ngramLength; i++) {
            nullString[i] = (char) 0;
        }
    }

    /**
     * Create a tokenizer that will send its output to the given
     * <code>Stage</code> and generate tokens for punctuation
     * if boolean sp (for "sendPunct") is true.
     * @param s The output stage to receive the generated tokens.
     * @param sp Flag indicating whether to transmit punctuation.
     * @param nuf Flag indicating not to generate unigrams for Asian chars.
     */
    public UniversalTokenizer(Stage s, boolean sp, boolean nuf) {
        super(s, sp);
        token = new char[32];
        tokLen = 0;
        lengths = new int[32];
        state = INITIAL;
        breakCharFlag = false;
        makeTokens = true;
        noUnigramsFlag = nuf;

        // pc is null char to start, otherwise pc carries across handleText
        // and handleEvent.
        pc = 0;
        pcl = 0;
        ngramLength = 2;
        nullString = new char[ngramLength];
        for(int i = 0; i < ngramLength; i++) {
            nullString[i] = (char) 0;
        }
    }

    /**
     * Create a tokenizer that will send its output to the given
     * <code>Stage</code> and generate tokens for punctuation
     * if boolean sp (for "sendPunct") is true.
     * @param s The output stage to receive the generated tokens.
     * @param sp Flag indicating whether to transmit punctuation.
     * @param nuf Flag indicating not to generate unigrams for Asian chars.
     * @param sendWhite Flag that causes generation of punctuation tokens
     *                  for runs of whitespace characters when sp is true.
     */
    public UniversalTokenizer(Stage s, boolean sp, boolean nuf,
            boolean sendWhite) {
        super(s, sp);
        token = new char[32];
        tokLen = 0;
        lengths = new int[32];
        state = INITIAL;
        breakCharFlag = false;
        makeTokens = true;
        noUnigramsFlag = nuf;
        this.sendWhite = sendWhite;

        // pc is null char to start, otherwise pc carries across handleText
        // and handleEvent.
        pc = 0;
        pcl = 0;
        ngramLength = 2;
        nullString = new char[ngramLength];
        for(int i = 0; i < ngramLength; i++) {
            nullString[i] = (char) 0;
        }
    }

    /**
     * A factory method to get a tokenizer.
     */
    public Tokenizer getTokenizer(Stage s, boolean sp) {
        return new UniversalTokenizer(s, sp);
    }
    /**
     * Blocks generation of unigram characters in between
     * character bigrams in runs of Asian characters.
     */
    public boolean noUnigramsFlag = true;

    /**
     * Blocks generation of transition events from and to null at the
     * beginning and ending of runs of Asian characters.
     */
    private static final boolean noEndFlag = true;

    /**
     * Causes all punctuation to cause breaks -- unlike SmartTokenizer,
     * which decides based on context when to treat some punctuation as
     * breaks.
     */
    private static final boolean simpleFlag = true;

    /**
     * Characters that should not cause breaks when simpleFlag is true,
     * even though they may be punctuation characters.  Note: You can't
     * make whitespace characters noBreakCharacters even if you put them
     * in this list.  This variable is public so that it can be changed.
     */
    public String noBreakCharacters = "";

    /**
     * Causes each break char to generate its own punctuation event, rather
     * than generating a single punctuation event for a sequence of
     * punctuation chars.
     */
    private static final boolean separateBreakFlag = false;

    @Override
    public void process(String text) {
        super.process(text);
        flush();
    }

    @Override
    public void text(CharSequence s) {

        //
        // We no longer care about character position - only word position.
        // For now, we'll just make "p" zero.  Next pass through this code
        // should include removing p and the character position pos.
        int p = 0;

        //
        // If we're not supposed to make tokens, then just add all of
        // this text to the current token.
        if(!makeTokens) {
            int newLen = tokLen + s.length();
            if(newLen >= token.length) {
                token = Arrays.copyOf(token, newLen + 32);
                lengths = Arrays.copyOf(lengths, newLen + 32);
            }
            // Add new characters into the token buffer.
            if(s instanceof String) {
                ((String) s).getChars(0, s.length(), token, tokLen);
            } else {
                for(int i = 0; i < s.length(); i++) {
                    token[tokLen++] = s.charAt(i);
                }
            }
            tokLen = newLen;
            return;
        }

        //
        // If we're collecting, adjust the end position of the current
        // token to be the position just before this text.
        if((state >= COLLECTING && state <= ASIAN) || whiteCount > 0) {
            end = p - 1;
        }
        pos = p;

        // Character length is 1 for all chars in a text block.
        cl = 1;
        for(int i = 0; i < s.length(); i++) {
            c = s.charAt(i);
            handleChar();
            pos++;
        }
    }

    @Override
    public void text(char[] text, int b, int e) {
        
        //
        // We no longer care about character position - only word position.
        // For now, we'll just make "p" zero.  Next pass through this code
        // should include removing p and the character position pos.
        int p = 0;
        if(authorFlag && traceFlag) { // debug
            logger.info(String.format("text: %d - %d", b, e));
        }

        //
        // If we're not supposed to make tokens, then just add all of
        // this text to the current token.
        if(!makeTokens) {
            int newLen = tokLen + e - b;
            if(newLen >= token.length) {
                token = Arrays.copyOf(token, newLen + 32);
                lengths = Arrays.copyOf(lengths, newLen + 32);
            }
            // Add new characters into the token buffer.
            System.arraycopy(text, b, token, tokLen, e - b);
            tokLen = newLen;
            return;
        }

        //
        // If we're collecting, adjust the end position of the current
        // token to be the position just before this text.
        if((state >= COLLECTING && state <= ASIAN) || whiteCount > 0) {
            end = p - 1;
        }
        pos = p;

        // Character length is 1 for all chars in a text block.
        cl = 1;
        for(int i = b; i < e; i++) {
            c = text[i];
            handleChar();
            pos++;
        }
    }

    /**
     * Handle a character to add to the token buffer.
     */
    protected void handleChar() {

        if(!makeTokens) {
            if(tokLen + 1 > token.length) {
                token = Arrays.copyOf(token, tokLen + 32);
                lengths = Arrays.copyOf(lengths, tokLen + 32);
            }
            token[tokLen] = c;
            lengths[tokLen++] = cl;
            return;
        }

        //
        // Break words at the maximum token length.
        if(tokLen >= maxTokLen) {
            if(state == ASIAN) {
                continueAsianFlag = true;
                if(ngramLength > 0) {
                    transitionString =
                            new String(token, 1 + tokLen - ngramLength,
                            ngramLength - 1);
                }
            }
            mkToken();
            // Note that mkToken sets tokLen back to zero afterwards
            // and clears the continue and resume Asian flags.
            if(state == ASIAN) {
                resumeAsianFlag = true;
            } else {
                state = INITIAL;
            }
            start = pos;
            end = start + cl - 1;
        }

        // The most common case not to break is lowercase alphabetic
        // characters: lowercase a...z.
        if(c <= 122 && c >= 97) {
            // Note: the first test roughly halves the ASCII character
            // space.
            switch(state) {
                case INITIAL:
                case WHITESPACE:
                    // We need to set the start and end positions.
                    if(whiteCount <= 0) {
                        start = pos;
                        end = pos + cl - 1;
                    } else {
                        end += cl;
                    }
                    break;
                case ASIAN:
                    mkToken();
                    start = pos;
                    end = start + cl - 1;
                    break;
                // Default case includes COLLECTING and DOLLAR
                // If it was DOLLAR, we want to change to COLLECTING, since
                // DOLLAR state is used to indicate that the previous char
                // was a single dollar sign.
                default:
                    end += cl;
                    break;
            }
            addChar();
            state = COLLECTING;
            // Save c as the previous character for next character.
            pc = c;
            pcl = cl;
        } // Space is the most common case to break.
        else if(c == 32) { //the next most frequent case, a single space
            switch(state) {
                case INITIAL:
                case WHITESPACE:
                    // We need to set the start and end positions.
                    if(this.sendWhite) {
                        if(whiteCount <= 0) {
                            start = pos;
                            end = pos + cl - 1;
                        } else {
                            end += cl;
                        }
                    }
                    break;
                case COLLECTING:
                case DOLLAR:
                case ASIAN:
                    // The transition from collecting to whitespace
                    // causes us to emit tokens.
                    mkToken();
                    break;
            }
            breakCharFlag = false;
            if(this.sendWhite) {
                if(whiteCount <= 0) {
                    start = pos;
                    end = pos + cl - 1;
                }
                addChar();
                whiteCount = tokLen;
            }
            state = WHITESPACE;
            // Save c as the previous character for next character.
            pc = c;
            pcl = cl;
        } // The next most common cases not to break are uppercase
        // alphabetic characters: uppercase A...Z.
        else if(c <= 90 && c >= 65) {
            switch(state) {
                case INITIAL:
                case WHITESPACE:
                    // We need to set the start and end positions.
                    if(whiteCount <= 0) {
                        start = pos;
                        end = pos + cl - 1;
                    } else {
                        end += cl;
                    }
                    break;
                case ASIAN:
                    mkToken();
                    start = pos;
                    end = start + cl - 1;
                    break;
                default:
                    end += cl;
                    break;
            }
            addChar();
            state = COLLECTING;
            // Save c as the previous character for next character.
            pc = c;
            pcl = cl;
        } // CJK characters (Chinese, Japanese, Korean)
        // to be tokenized with bigram tokens.
        // (Put this test here so these languages will tokenize
        // more efficiently and it doesn't cost much for the non CJK
        // languages.)
        else if(isAsian(c)) {
            switch(state) {
                case INITIAL:
                case WHITESPACE:
                    // We need to set the start and end positions.
                    if(whiteCount <= 0) {
                        start = pos;
                        end = pos + cl - 1;
                    } else {
                        end += cl;
                    }
                    state = ASIAN;
                    break;
                case COLLECTING:
                case DOLLAR:
                    mkToken();
                    start = pos;
                    end = start + cl - 1;
                    state = ASIAN;
                    break;
                case ASIAN:
                    end += cl;
                    break;
            }
            addChar();
            // Save c as the previous character for next character.
            pc = c;
            pcl = cl;
        } // Special treatment for some whitespace characters for Asian
        // languages and for null:
        else if(c == 0 ||
                (state == ASIAN &&
                (c <= 13 && c >= 10)) // Linefeed, PageUp, Page, Return
                ) {
            // Do nothing, treat it as if the character wasn't even there.
        } // The rest of the white space characters for break:
        else if((c == 13) || // Return
                (c <= 12 && c >= 9) || // Tab, Linefeed, PageUp, Page
                (c == 160 || c <= 4) || // nbsp, STX, SOT, Enter, EOT
                (c > 255 && // any higher unicode whitespace
                Character.isWhitespace(c))) {
            // ASCII character 160 (nbsp) is nonbreak whitespace.
            // Java treats it as nonwhite and nonletter, but
            // we need to treat it as white, since it's used for
            // formatting in html files and some word processors.
            switch(state) {
                case INITIAL:
                case WHITESPACE:
                    // We need to set the start and end positions.
                    if(this.sendWhite) {
                        if(whiteCount <= 0) {
                            start = pos;
                            end = pos + cl - 1;
                        } else {
                            end += cl;
                        }
                    }
                    break;
                case COLLECTING:
                case DOLLAR:
                case ASIAN:
                    // The transition from collecting to whitespace
                    // causes us to emit tokens.
                    mkToken();
                    break;
            }
            breakCharFlag = false;
            if(this.sendWhite) {
                if(whiteCount <= 0) {
                    start = pos;
                    end = pos + cl - 1;
                }
                addChar();
                whiteCount = tokLen;
            }
            state = WHITESPACE;
            // Save c as the previous character for next character.
            pc = c;
            pcl = cl;
        } // If simpleFlag is true, then don't break for letter or digit
        // or specifically listed noBreakCharacters.
        else if(simpleFlag &&
                (isLetterOrDigit(c) ||
                (noBreakCharacters.indexOf(c) > -1))) {
            switch(state) {
                case INITIAL:
                case WHITESPACE:
                    // We need to set the start and end positions.
                    if(whiteCount <= 0) {
                        start = pos;
                        end = pos + cl - 1;
                    } else {
                        end += cl;
                    }
                    break;
                case ASIAN:
                    mkToken();
                    start = pos;
                    end = start + cl - 1;
                    break;
                default:
                    end += cl;
                    break;
            }
            addChar();
            state = COLLECTING;
            // Save c as the previous character for next character.
            pc = c;
            pcl = cl;
        } // Otherwise, if simpleFlag is true, then it's punct, so break.
        else if(simpleFlag) {
            switch(state) {
                case INITIAL:
                case WHITESPACE:
                    // We need to set the start and end positions.
                    if(whiteCount <= 0) {
                        start = pos;
                        end = pos + cl - 1;
                    } else {
                        end += cl;
                    }
                    break;
                case COLLECTING:
                case DOLLAR:
                case ASIAN:
                    if(tokLen > 0) {
                        mkToken();
                        start = pos;
                    }
                    end += cl;
                    break;
            }
            addChar();
            breakCharFlag = true;
            state = COLLECTING;
            // Save c as the previous character for next character.
            pc = c;
            pcl = cl;
        } // The next most common cases not to break are the digits:
        // numbers 0...9
        else if((c <= 57 && c >= 48) ||
                (c > 255 && Character.isDigit(c))) {
            switch(state) {
                case INITIAL:
                case WHITESPACE:
                    // We need to set the start and end positions.
                    if(whiteCount <= 0) {
                        start = pos;
                        end = pos + cl - 1;
                    } else {
                        end += cl;
                    }
                    state = COLLECTING;
                    break;
                case DOLLAR:

                    // If c is '$' and it's followed by a number or
                    // preceded by a number, then break it out from
                    // whatever precedes and follows it.  The following
                    // handles the case when followed by a number.

                    // What if we're at the end of a text block and
                    // the next char is a digit, but comes in as a
                    // long char or in the next handleText?
                    // Answer: use DOLLAR state to remember this
                    // condition across calls to handleText and
                    // handleEvent.

                    // Since char c is a digit, don't include the prev
                    // dollar sign with it.  This breaks "$10-$20" into $
                    // 10 - $ 20, but leaves $foo, foo$, and foo$fie
                    // unsplit.  Note: mkToken will only allow a single
                    // $ at the ends of a word.

                    // Pull off last char in token (the $), force mkToken,
                    // then put the $ back in and call mkToken again.
                    if(tokLen > 1) { // There's more than just the $ in token
                        // Back up one character.
                        tokLen--;
                        pos -= pcl;
                        end -= pcl;
                        // Generate tokens from token with pc removed.
                        // Note: If breakCharFlag == true because of pc and only pc
                        // this is benign.  It only causes some extra checking.
                        mkToken();
                        // Start a new token with just pc in it, and continue.
                        start = pos;
                        end = start + pcl - 1;
                        addChar();
                        pos += pcl;
                    }
                    // Now generate token for the $
                    breakCharFlag = true;
                    mkToken();
                    start = pos;
                    end = start + cl - 1;
                    state = COLLECTING;
                    break;
                case ASIAN:
                    mkToken();
                    start = pos;
                    end = start + cl - 1;
                    state = COLLECTING;
                    break;
                default:
                    end += cl;
                    break;
            }
            addChar();
            // Save c as the previous character for next character.
            pc = c;
            pcl = cl;
        } // More cases not to break, some of which are conditional breaks:
        else if((c == 46 || c == 45) || // .-
                (c == 39 || c == 95) || // '_
                (c <= 44 && c >= 42) || // *+,
                (c == 58 || c == 47) || // :/
                (c == 64 || c == 38) || // @&
                (c == 35 || c == 92) || // #\
                (c == 36)) {
            switch(state) {
                case INITIAL:
                case WHITESPACE:
                    // We need to set the start and end positions.
                    if(whiteCount <= 0) {
                        start = pos;
                        end = pos + cl - 1;
                    } else {
                        end += cl;
                    }
                    addChar();
                    if(c == '$') {
                        state = DOLLAR;
                    } else {
                        state = COLLECTING;
                    }
                    breakCharFlag = true;
                    break;
                case ASIAN:
                    mkToken();
                    start = pos;
                    end = start + cl - 1;
                    addChar();
                    if(c == '$') {
                        state = DOLLAR;
                    } else {
                        state = COLLECTING;
                    }
                    breakCharFlag = true;
                    break;
                default:

                    // Break on two or more of these chars (-.'_*), but not on
                    // just one.

                    if(c == pc && ("-.'_*".indexOf(c) > -1)) {
                        // If it's a run of the same char, keep going; don't
                        // break it.  The first time we encounter p == pc, we
                        // induce a break before pc and then start a new token
                        // with pc.  If we subsequently encounter another of the
                        // same character, then all that will be in the token
                        // buffer is a sequence of two or more of those
                        // characters and we don't want to break that sequence.
                        // Note: tokLen points to the next unused slot in token.
                        // Note: if pc is the only char in token, no need to do
                        // this adjustment.
                        if(tokLen > 1 && c != token[tokLen - 2] &&
                                // The last character in token must already be equal to pc or else
                                // something is wrong with pc tracking, in which
                                // case, don't do this.
                                pc == token[tokLen - 1]) {
                            // Back up one character.
                            tokLen--;
                            pos -= pcl;
                            end -= pcl;
                            // Generate tokens from token with pc removed.
                            // Note: If breakCharFlag == true because of pc and
                            // only pc, then this is benign.  It only causes some
                            // extra checking.
                            mkToken();
                            // Start a new token with just pc in it, and continue.
                            start = pos;
                            end = start + pcl - 1;
                            addChar();
                            pos += pcl;
                        }
                        end += cl;
                        addChar();
                        breakCharFlag = true;
                        state = COLLECTING;
                    } // If c is '$' and it's followed by a number or preceded
                    // by a number, then break it out from whatever precedes
                    // and follows it.  The following handles the case when
                    // preceded by a number.
                    else if(c == '$' && isDigit(pc)) {
                        mkToken();
                        start = pos;
                        end = start + cl - 1;
                        addChar();
                        breakCharFlag = true;
                        // Since prev char is a digit, don't include this dollar sign with it.
                        // This breaks "10$-20$" into 10 $ - 20 $, but leaves
                        // $foo, foo$, and foo$fie unsplit.
                        // Note: mkToken will only allow a single $ at the ends
                        // of a word.
                        mkToken();
                        state = WHITESPACE;
                    } else {
                        end += cl;
                        addChar();
                        breakCharFlag = true;
                        if(c == '$' && pc != '$') {
                            // Remember that this char was a dollar to see if next
                            // is a digit.
                            state = DOLLAR;
                        } else {
                            state = COLLECTING;
                        }
                    }
                    break;
            }
            // Save c as the previous character for next character.
            pc = c;
            pcl = cl;
        } // More cases to break, but don't lose the character.
        else if((c <= 96 && c >= 0) || // everything below 97(a) not already covered
                (c == 210 || c == 211) || // (smart quotes) ('"' is included in <= 96)
                (c >= 123 && c <= 125) // {|}
                ) {
            switch(state) {
                case INITIAL:
                case WHITESPACE:
                    if(whiteCount <= 0) {
                        start = pos;
                        end = pos + cl - 1;
                    } else {
                        end += cl;
                    }
                    break;
                case COLLECTING:
                case DOLLAR:
                case ASIAN:
                    if(separateBreakFlag ||
                            isLetterOrDigit(pc) ||
                            ("-:*+,./'_ @&#\\".indexOf(pc) > -1) ||
                            (state == ASIAN)) {
                        // If the static final flag separateBreakFlag is set,
                        // or if making a transition from alphanum or ASIAN,
                        // or if preceded by the specified internal chars,
                        // then the transition from collecting to break char
                        // causes us to emit the token gathered so far.
                        mkToken();
                        start = pos;
                    }
                    end += cl;
                    break;
            }
            addChar();
            state = COLLECTING;
            breakCharFlag = true;
            // Save c as the previous character for next character.
            pc = c;
            pcl = cl;
        } // More cases not to break -- any other cases of letter or digit.
        else if(isLetterOrDigit(c)) {
            switch(state) {
                case INITIAL:
                case WHITESPACE:
                    // We need to set the start and end positions.
                    if(whiteCount <= 0) {
                        start = pos;
                        end = pos + cl - 1;
                    } else {
                        end += cl;
                    }
                    break;
                case ASIAN:
                    mkToken();
                    start = pos;
                    end = start + cl - 1;
                    break;
                default:
                    end += cl;
                    break;
            }
            addChar();
            state = COLLECTING;
            // Save c as the previous character for next character.
            pc = c;
            pcl = cl;
        } // Anything other than the above cases, we collect as break
        // chars for possible later separation.
        else {
            switch(state) {
                case INITIAL:
                case WHITESPACE:
                    // We need to set the start and end positions.
                    if(whiteCount <= 0) {
                        start = pos;
                        end = pos + cl - 1;
                    } else {
                        end += cl;
                    }
                    break;
                case COLLECTING:
                case DOLLAR:
                case ASIAN:
                    if(separateBreakFlag ||
                            isLetterOrDigit(pc) ||
                            ("-:*+,./'_ @&#\\".indexOf(pc) > -1) ||
                            (state == ASIAN)) {
                        // If the static final flag separateBreakFlag is set,
                        // or if making a transition from alphanum or ASIAN,
                        // or if preceded by the specified internal chars,
                        // then the transition from collecting to break char
                        // causes us to emit the token gathered so far.
                        mkToken();
                        start = pos;
                    }
                    end += cl;
                    break;
            }
            addChar();
            breakCharFlag = true;
            state = COLLECTING;
            // Save c as the previous character for next character.
            pc = c;
            pcl = cl;
        }
    }

    /**
     * Add a character to the buffer that we're building for a token.
     */
    protected void addChar() {

        //
        // First see if token buffer needs to be expanded.
        // Note: tokLen points to the next unused slot in token.
        if(token.length <= tokLen) {
            token = Arrays.copyOf(token, tokLen + 32);
            lengths = Arrays.copyOf(lengths, tokLen + 32);
        }

        lengths[tokLen] = cl;
        token[tokLen++] = c;
    }

    /**
     * Finish any final token left in the buffer.
     */
    public void flush() {
        mkToken();
        state = INITIAL;

        // Set pc to start as null character after a breaking event.
        pc = 0;
        pcl = 0;
    }

    /**
     * Reset state of tokenizer to clean slate.
     */
    @Override
    public void reset() {
        super.reset();
        tokLen = 0;
        whiteCount = 0;
        continueAsianFlag = false;
        resumeAsianFlag = false;
        state = INITIAL;
        breakCharFlag = false;
        makeTokens = true;
        pc = 0;
        pcl = 0;
        ngramLength = 2;
        wordNum = 1;
    }

    /**
     * Will the given event break a token?
     */
    protected boolean isBreakingEvent(int type, int subType) {
        return true;
    }

    /**
     * Break our collected text into as many as three pieces.  The three
     * pieces are the preToken, the token, and the postToken.  The preToken
     * includes any initial punctuation that is removed from the token,
     * the token is the word, and the postToken is any final punctuation
     * that is removed from the token.
     */
    protected void mkToken() {

        //
        // Don't produce tokens if we're not supposed to!
        if(!makeTokens) {

            //
            // If we're supposed to index, then pass down the whole thing
            // as a token.
            if(indexed && tokLen > 0) {
                downstream.token(new Token(new String(token, 0, tokLen),
                        wordNum++,
                        state == ASIAN ? Token.BIGRAM : Token.NORMAL,
                        start, end + 1));
            }
            tokLen = 0;
            whiteCount = 0;
        }

        //
        // Don't generate empty tokens.
        if(tokLen <= 0) {
            whiteCount = 0;
            return;
        }

        int i = 0;
        int j = tokLen - 1;

        //
        // If whiteCount > 0 and sendWhiteFlag is true, then there's
        // whitespace to send as a punctuation event.
        if(whiteCount > 0 && this.sendWhite) {
            if(sendPunct) {
                downstream.punctuation(new Token(new String(token, 0,
                        whiteCount),
                        wordNum,
                        Token.PUNCT,
                        start, start + whiteCount));
            }
            if(authorFlag && traceFlag) {
                System.out.println("pwcomment: whiteCount is " + whiteCount +
                        " and tokLen is " + tokLen);//debugging
                String sentNote = "";
                if(!sendPunct) {
                    sentNote = " not sent";
                }
                String prefixString = new String(token, 0, whiteCount);
                System.out.println("pw: " + start + "-" + (start + whiteCount) +
                        ":" + prefixString + " " + showCodes(prefixString) +
                        sentNote);
            }
        }

        for(int k = 0; k < whiteCount; k++) {
            start += lengths[k];
        }

        i = whiteCount;

        //
        // The initial positions for the pre and postToken.
        int preStart = start;
        int preEnd = start;
        int postStart = end;
        int postEnd = end;
        int increment;

        // Only try to build preTokens and postTokens if there were some break
        // chars.
        if(breakCharFlag) {

            //
            // Build the preToken.
            while(i < tokLen && !(isLetterOrDigit(token[i]) ||
                    (simpleFlag &&
                    noBreakCharacters.indexOf(token[i]) > -1))) {

                //
                // Check whether this is an allowable initial punctuation
                // character, and if so, if the next character is a letter or
                // digit, and if we are at the beginning of the token.  If so,
                // then don't make a preToken.  We allow these punctuation
                // marks to be included in the token, but only when there is
                // only one of them -- e.g., we don't want ... as a prefix
                // included in a token, although .txt and .com are ok.
                // However, if simpleFlag is true, make a preToken anyway.
                if((i == whiteCount) && (i < j) && !simpleFlag &&
                        checkInitialPunc(token[i]) &&
                        isLetterOrDigit(token[i + 1])) {
                    break;
                }

                //
                // Adjust the start position of the word and the end position
                // of the preToken.
                increment = lengths[i];
                start += increment;
                preEnd += increment;

                i++;
            }

            //
            // If there's anything left, try to get the post token.
            if(i < tokLen) {

                //
                // Work backwards from the end of the token, picking off
                // terminal punctuation.
                while(j >= i && !(isLetterOrDigit(token[j]) ||
                        (simpleFlag &&
                        noBreakCharacters.indexOf(token[j]) > -1))) {

                    //
                    // See whether this is an acceptable trailing punctuation
                    // character coming after a letter or digit.  If it is, we
                    // won't strip it (if it is the last character of token).
                    if((j == tokLen - 1) && (j > i) &&
                            checkTrailingPunc(token[j]) &&
                            isLetterOrDigit(token[j - 1])) {
                        break;
                    }

                    //
                    // Adjust the positions for the token and the postToken.
                    increment = lengths[j];
                    end -= increment;
                    postStart -= increment;

                    j--;
                }
            }

        } // end of preToken and postToken processing

        //
        // At this point we want to fix up the cases where a period should
        // be included with the token, rather than the postToken.  We only
        // need to check this when the first character of the postToken
        // exists and is a period.  E.g., "U.S." includes the final period.
        // Note: j points to the last char of the word, not the first char
        // of the postToken.
        if((j + 1 < tokLen) && (j > 1) && (token[j + 1] == '.') &&
                (token[j - 1] == '.')) {

            //
            // If the last character of the token is upper case, and the next
            // to last character is a period, and there are other characters,
            // then we're going to say that this is an abbreviation and the
            // final period is part of it, so we want to add the period back
            // to the word.  We'll also adjust the start and end positions.
            if(Character.isUpperCase(token[j])) {
                increment = lengths[j + 1];
                end += increment;
                postStart += increment;
                j++;
            }
        }

        //
        // If i points past the start of the string, then there's a
        // preToken.
        if(i > whiteCount) {
            if(sendPunct) {
                downstream.punctuation(new Token(new String(token, whiteCount,
                        i - whiteCount),
                        wordNum,
                        Token.PUNCT,
                        preStart, preEnd));
            }
            if(authorFlag && traceFlag) {
                String sentNote = "";
                if(!sendPunct) {
                    sentNote = " not sent";
                }
                String prefixString = new String(token, whiteCount,
                        i - whiteCount);
                System.out.println("pr: " + preStart + "-" + preEnd + ":" +
                        prefixString + " " + showCodes(prefixString) + sentNote);
            }
        }

        //
        // If there's stuff between i and j, then there's a word token.
        // Note: j points to the last char of the word, not the first char
        // of the postToken.
        if(i < tokLen && j >= i) {

            tokenLength = (j + 1) - i;
            tokenString = new String(token, i, tokenLength);
            if(state != ASIAN ||
                    (tokenLength == 1 && !resumeAsianFlag && noUnigramsFlag)) {

                //
                // Only generate the token if we're either not ignoring long
                // tokens or if the token is short enough.
                if(!ignoreLongTokens || tokenLength < ignoreableTokenLength) {
                    downstream.token(new Token(tokenString,
                            wordNum++,
                            start, end + 1));
                    if(authorFlag && traceFlag) {
                        System.out.println("tk: " + start + "-" + (end + 1) +
                                ":" + tokenString //+" "+showCodes(tokenString)
                                );
                    }
                }
            } else {
                //
                // This is where the ngrams are generated.
                int left, right, charLength, prevLength;
                int position = start;
                int lp; // left position
                int rp; // right position
                String ngramString;
                for(int k = 0; k <= tokenLength; k++) {
                    if(k < tokenLength) { // for chars in the tokenString
                        charLength = lengths[k + whiteCount];
                    } else {
                        charLength = 0; // for transition events beyond tokenString
                    }
                    if(k > 0) { // for chars in the tokenString
                        prevLength = lengths[k + whiteCount - 1];
                    } else {
                        prevLength = 0; // for transition events before tokenString
                    }
                    for(int even = 1; even >= 0; even--) {
                        for(int n = even; n < ngramLength; n += 2) {
                            // Int n is one less than the size of the ngram to make;
                            // The boolean even keeps track of whether the ngram size
                            // is odd (even == 0).  For odd sized ngrams, generate
                            // tokens centered on this char with the beginning
                            // (position) and ending (position+length).
                            lp = position;
                            if(even == 0) {
                                // This is an odd-length ngram.
                                left = k - n / 2; // for k == 0 and n == 0, this is  0
                                right = left + n + 1;
                                ngramString = tokenSubstring(left, right);
                                if(n > 1) {
                                    // Give contextual variants zero length
                                    rp = position;
                                } else {
                                    rp = position + charLength;
                                }
                            } else {
                                // This is an even-length ngram.
                                left = k - (n + 1) / 2; // for k == 0 and n == 0, this is  0
                                right = left + n + 1;
                                ngramString = tokenSubstring(left, right);
                                rp = position;
                                if(noUnigramsFlag) {
                                    lp = position - prevLength;
                                }
                            }
                            // When beyond the end of tokenString, only generate
                            // transition events, and don't duplicate one that is
                            // redundant with one that has already been generated.
                            if((k < tokenLength || (even == 1)) && !redundant &&
                                    !(noUnigramsFlag && even == 0)) {
                                downstream.token(new Token(ngramString,
                                        wordNum++,
                                        lp, rp));
                                if(authorFlag && traceFlag) {
                                    System.out.println("ng: " + lp + "-" + rp +
                                            ":" + ngramString + " " + showCodes(
                                            ngramString));
                                }
                            }
                        }
                    }
                    position += charLength;
                }
            }
        }

        //
        // If we moved j, then there's a postToken.
        // Note: j points to the last char of the word, not the first char
        // of the postToken.
        if(j + 1 < tokLen && sendPunct) {

            downstream.punctuation(new Token(new String(token, j + 1,
                    tokLen - (j + 1)),
                    wordNum, Token.PUNCT,
                    postStart + 1, postEnd + 1));
            if(authorFlag && traceFlag) {
                String suffixString = new String(token, j + 1, tokLen - (j + 1));
                System.out.println("po: " + (postStart + 1) + "-" +
                        (postEnd + 1) + ":" + suffixString + " " + showCodes(
                        suffixString));
            }
        }
        continueAsianFlag = false;
        resumeAsianFlag = false;

        // Reset variables for next token.
        tokLen = 0;
        whiteCount = 0;
        breakCharFlag = false;
    }
    // Used to maintin continuity of ngrams in long runs of Asian chars.
    protected boolean continueAsianFlag = false;

    protected boolean resumeAsianFlag = false;

    protected String transitionString = "";

    // Used to keep track of redundant ngrams.
    protected boolean redundant = false;

    /**
     * Determine token substring to generate for ngram from left to right,
     * where left and right are not yet clamped by the ends of tokenString.
     *
     * @param left The index of the first character of the ngram token.
     * @param right The index of the position after the last character.
     * @return a substring of the token
     */
    protected String tokenSubstring(int left, int right) {
        int lp = left;
        int rp = right;
        String ls = "";
        String rs = "";
        redundant = false;
        if(left < 0) {
            lp = 0;
            ls = new String(nullString, 0, -left);
            if(resumeAsianFlag) {
                // Generate left string ls from transitionString
                ls = transitionString;
            } else if(noEndFlag) {
                redundant = true; // Don't generate this one.
            }
        }
        if(right > tokenLength) {
            rp = tokenLength;
            rs = new String(nullString, 0, right - tokenLength);
            if(continueAsianFlag || tokenLength == 1 || !noUnigramsFlag) {
                redundant = true; // Don't want to generate this one.
            } else if((left < -1) && (right > tokenLength + 1)) {
                // overlaps word at both ends and by more than one char,
                // hence redundant with a shorter ngram.
                redundant = true;
            }
        }
        String substring = tokenString.substring(lp, rp);
        if(left < 0 || right > tokenLength) {
            substring = ls + substring + rs;
        }
        return substring;
    }

    /**
     * Determine whether char is acceptable as a final char of a token.
     *
     * @param c The char to be tested.
     */
    protected boolean checkTrailingPunc(char c) {
        if(c == '/' || c == '$') {
            return true;
        } else {
            return false;
        }
    }

    /**
     * Determine whether char is acceptable as an initial char of a token.
     *
     * @param c The char to be tested.
     */
    protected boolean checkInitialPunc(char c) {
        if((c <= 47 && c >= 45) || // -./
                (c == 64 || c == 33) || // ?!
                (c == 36 || c == 63) // $@
                ) {
            return true;
        } else {
            return false;
        }
    }

    /**
     * A quick check for whether a character should be kept in a word or
     * should be removed from the word if it occurs at one of the ends.  An
     * approximation of Character.isLetterOrDigit, but is faster and more
     * correct, since it doesn't count the smart quotes as letters.
     * @param c The character to check.
     */
    public static final boolean isLetterOrDigit(char c) {
        if((c <= 122 && c >= 97) || // most frequent: lowercase a...z
                (c <= 90 && c >= 65) || // frequent: uppercase A...Z
                (c <= 57 && c >= 48) // frequent: numbers 0...9
                ) {
            return true;
        } else if((c <= 96) || // includes whitespace
                (c == 210 || c == 211) || // (smart quotes)
                (c >= 123 && c <= 127) // {|}~DEL
                ) {
            return false;
        } else if((c >= 3021 && c <= 3029) || // Hangzhou-style numerals
                (c >= 65 && c <= 90) || // frequent: uppercase A...Z
                (c >= 48 && c <= 57) // frequent: numbers 0...9
                ) {
            return true;
        } else {
            return Character.isLetterOrDigit(c);
        }
    }

    /**
     * A quick check for whether a character is a digit.
     * @param c The character to check
     */
    public static final boolean isDigit(char c) {
        if((c <= 57 && c >= 48) // most frequent: ASCII numbers 0...9
                ) {
            return true;
        } else if(c <= 255) {
            return false;
        } else {
            return Character.isDigit(c);
        }
    }

    /**
     * A quick check for whether a character is whitespace.
     * @param c The character to check
     */
    public static final boolean isWhitespace(char c) {
        //test for white space
        if((c == 32) || // Space
                (c <= 13 && c >= 9) || // Tab, Linefeed, PageUp, Page, Return
                (c <= 4 && c >= 1) // STX, SOT, ETX (Enter), EOT
                ) {
            return true;
        } else if(c <= 255) {
            return false;
        } else {
            return Character.isWhitespace(c);
        }
    }
    public static final boolean excludeKanaFlag = false;

    /**
     * A quick check for an Asian or a character in a language
     * that may not separate words with whitespace (includes Arabic,
     * CJK, and Thai). Uses Unicode Standard Version 2.0.
     * @param c The character to check
     */
    public static final boolean isAsian(char c) {
        // Test for characters that may not separate words with white
        // space and therefore require bigram treatment.
        // Uses Unicode Standard Version 2.0.
        if(c > '\u3000' && c <= '\uD7FF') {           // (CJK Characters)
            if(!excludeKanaFlag) {
                return true;
            } else if(c <= '\u30FF' && c >= '\u3040') {   // - Hiragana and Katakana
                //                ( c >= '\u3040' && c <= '\u309F')      // - Hiragana
                //                ( c >= '\u30A0' && c <= '\u30FF')      // - Katakana
                return false;
            } else {
                return true;
            }
        } else if((c >= '\u0600' && c <= '\u06FF') || // (Arabic)

                (c >= '\uF900' && c <= '\uFAFF') || // (CJK Compatibility Ideographs)

                (c >= '\u1100' && c <= '\u11FF') || // (Hangul Jamo)

                (c >= '\uFB50' && c <= '\uFE2F') || // (Arabic Presentation Forms-A)
                (c >= '\uFE30' && c <= '\uFE4F') || // (CJK Compatibility Forms)

                (c >= '\uFE70' && c <= '\uFEFF') || // (Arabic Presentation Forms-B)

                (c >= '\uFF60' && c <= '\uFFDF') || // (CJK Half Width Forms)

                (c >= '\u0E00' && c <= '\u0E7F') || // (Thai)
                (c >= '\u0E80' && c <= '\u0EFF') || // (Lao)
                (c >= '\u0F00' && c <= '\u0FBF') || // (Tibetan)

                (c >= '\u0B80' && c <= '\u0BFF') || // (Tamil)
                (c >= '\u0C00' && c <= '\u0C7F') || // (Telugu)
                (c >= '\u0C80' && c <= '\u0CFF') || // (Kannada)
                (c >= '\u0D00' && c <= '\u0D7F') || // (Malayalam)

                (c >= '\u10A0' && c <= '\u10FF') || // (Georgian)

                false) {
            return true;
        } else {
            return false;
        }
    }

    /**
     * A function for viewing a string containing nonprintable
     * ascii and unicode characters.
     * @param charString the string to convert
     */
    public static final String showCodes(String charString) {
        String output = "";
        int code;
        for(int i = 0; i < charString.length(); i++) {
            code = (int) (charString.charAt(i));
            output = output + "(" + code + ")" + Integer.toHexString(code);
        }
        return output;
    }

    static final int INITIAL = 0;

    static final int COLLECTING = 1;

    static final int WHITESPACE = 2;

    static final int DOLLAR = 3;

    static final int ASIAN = 4;

    /**
     * The state of the tokenizer determined by previous history
     * (will be one of INITIAL, COLLECTING, WHITESPACE, DOLLAR, ASIAN).
     */
    int state;

    /**
     * The start position for the current token.
     */
    int start = 0;

    /**
     * The end position for the current token.
     */
    int end = 0;

    char[] token;

    int[] lengths;

    int tokLen;

    /**
     * The number of whitespace chars that precede the current token.
     */
    int whiteCount = 0;

    /**
     * A boolean to record and signal the presence of a break char in token.
     */
    boolean breakCharFlag;

    static final boolean ignoreLongTokens = false;

    static final int ignoreableTokenLength = 40;

    /**
     * A flags to enable debugging traces.
     */
    static final boolean authorFlag = false;

    public boolean traceFlag = false;

    /**
     * Variables to hold the current char (c) and previous char (pc) and their
     * lengths (cl, pcl) and the current file position (pos).  Note, pos is
     * used by checkSentenceEnd as well as handleText and handleChar.
     */
    char c, pc;

    int cl, pcl, pos;

    protected int tokenLength;

    protected int ngramLength;

    protected char[] nullString;

    protected String tokenString;

    protected static final Logger logger = Logger.getLogger(UniversalTokenizer.class.getName());

} // UniversalTokenizer.java
