/*
 * Copyright 2007-2008 Sun Microsystems, Inc. All Rights Reserved.
 * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER
 * 
 * This code is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License version 2
 * only, as published by the Free Software Foundation.
 * 
 * This code is distributed in the hope that it will be useful, but
 * WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
 * General Public License version 2 for more details (a copy is
 * included in the LICENSE file that accompanied this code).
 * 
 * You should have received a copy of the GNU General Public License
 * version 2 along with this work; if not, write to the Free Software
 * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
 * 02110-1301 USA
 * 
 * Please contact Sun Microsystems, Inc., 16 Network Circle, Menlo
 * Park, CA 94025 or visit www.sun.com if you need additional
 * information or have any questions.
 */
package com.sun.labs.minion.retrieval;

import com.sun.labs.minion.FieldInfo;
import com.sun.labs.minion.indexer.partition.InvFileDiskPartition;
import java.util.Arrays;
import java.util.Iterator;
import java.util.List;
import java.util.logging.Logger;

/**
 * An abstract class for all proximity operators.  This class includes the
 * methods common to all such operators.
 */
public abstract class Proximity extends Operator {

    /**
     * The maximum number of terms that may be missing from a qualifying
     * passage.
     */
    protected int maxMissing;

    /**
     * The minimum window size for a qualifying passage.
     */
    protected int minWindow = 0;

    /**
     * The maximum window size for a qualifying passage.
     */
    protected int maxWindow = 350;

    /**
     * The penalty to assign for a gap in a passage, per word.
     */
    protected float gapPenalty = 0.1f;

    /**
     * The additionaly penalty to assign to a gap between terms that are
     * out of order in the passage.
     */
    protected float oooPenalty = 0.25f;

    /**
     * The operands in the order in which they appear in the query.
     */
    protected QueryElement[] orderedOps;

    /**
     * The dictionary terms from the query, in the order given in the query.
     */
    protected DictTerm[] terms;

    /**
     * Which of the terms in the query were generated by ONECHAR operators?
     */
    protected boolean[] ocTerms;

    /**
     * Whether we need to store passages or no.
     */
    protected boolean storePassages;

    static final Logger logger = Logger.getLogger(Proximity.class.getName());

    /**
     * Builds a proximity operator from a list of operands.
     */
    public Proximity(List operands) {
        super(operands);

        //
        // Normally we deal with operands in size order, but for proximty
        // we'll need to deal with them in query order.  We'll also need to
        // look at just the terms, so we'll separate things out here.
        //
        // Note that we're only interested in dictionary terms:  parametric
        // query terms will be treated like embedded query operators!
        orderedOps = new QueryElement[operands.size()];
        terms = new DictTerm[operands.size()];
        ocTerms = new boolean[operands.size()];
        for(Iterator i = operands.iterator(); i.hasNext();) {
            QueryElement qe = (QueryElement) i.next();
            orderedOps[qe.order] = qe;
            if(qe instanceof DictTerm) {
                terms[qe.order] = (DictTerm) qe;

                //
                // We'll need to load positions!
                terms[qe.order].setLoadPositions(true);
            }
        }
    } // Proximity constructor

    /**
     * Sets the out-of-order penalty.
     */
    protected void setOOO(float p) {
        oooPenalty = p;
    }

    /**
     * Sets the gap penalty.
     */
    protected void setGap(float p) {
        gapPenalty = p;
    }

    /**
     * Sets the maximum window.
     */
    protected void setWindow(int w) {
        maxWindow = w;
    }

    /**
     * Sets the flag indicating whether we should store passages when doing
     * retrieval.
     */
    protected void setStorePassages(boolean b) {
        for(Iterator i = operands.iterator(); i.hasNext();) {
            QueryElement qe = (QueryElement) i.next();
            if(qe instanceof Proximity) {
                ((Proximity) qe).setStorePassages(b);
            }
        }
        storePassages = b;
    }

    /**
     * Evaluates a set of terms against the current constraints, returning
     * the results.
     *
     * @param candidates A candidate set of documents, generated by one of
     * the subclasses.
     * @param terms The terms for which we wish to compute the proximity
     * constraints.  The list must contain instances of
     * <code>DictTerm</code>.
     */
    protected ArrayGroup evalTerms(ArrayGroup candidates, List<DictTerm> terms) {

        float maxScore = Float.MIN_VALUE;
        int nPerfect = 0;


        //
        // A quick check for a single term query, which we'll just handle
        // as though it were not a proximity query, making sure to
        // intersect with the candidate set.
        if(terms.size() == 1) {
            DictTerm term = terms.get(0);
            ArrayGroup ag = term.eval(candidates);
            ag.width = 1;

            //
            // If we're not supposed to store positions, we can pack it
            // in.
            if(!storePassages) {
                return ag;
            }

            //
            // Figure out what fields we need.
            int[] doFields;
            doFields = new int[part.getPartitionManager().getMetaFile().size() + 1];
            for(FieldInfo fi : searchFields) {
                doFields[fi.getID()] = 1;
            }

            int[][] fieldPosns;
            int[] tops = new int[1];

            //
            // Otherwise, we need to add the positions.
            for(int i = 0; i < ag.size; i++) {
                fieldPosns = term.getPositions(ag.docs[i]);

                for(int f = 0; f < doFields.length; f++) {
                    if(doFields[f] == 0) {
                        continue;
                    }

                    int[] fposn = fieldPosns[f];
                    if(fposn == null) {
                        continue;
                    }
                    int n = fposn[0];
                    for(int j = 1; j <= n; j++) {
                        tops[0] = fposn[j];
                        ag.addPassage(i, f, tops, 0);
                    }
                }
            }

            return ag;
        }

        //
        // A new scored group for our return set, which will never be
        // larger than our candidate set size.
        ScoredGroup ret = new ScoredGroup(candidates.size);
        ret.width = terms.size();

        //
        // A scored version of the candidates set.
        ScoredGroup scoredCandidates = candidates.getScored();

        //
        // A place to keep the positions that we get from each term.  I
        // know a 3D array is gross, but each term will give us a 2D array,
        // and we need to have all of them around so that we can do a
        // field-by-field search.
        int[][][] fieldPosns = new int[terms.size()][][];

        //
        // A place to store our columns and their lengths.
        int[][] columns = new int[terms.size()][16];
        int[] lens = new int[terms.size()];

        //
        // Now, we'll go field by field and build up the positions for that
        // field.  If we have some fields that we're supposed to search,
        // we'll do only those, otherwise, we'll do everything.
        int[] doFields;
        doFields = new int[((InvFileDiskPartition) part).getPartitionManager().
                getMetaFile().size() + 1];
        for(FieldInfo fi : searchFields) {
            doFields[fi.getID()] = 1;
        }

        //
        // OK, here we go. For each candidate document, we will want to
        // pull the positions for the terms and check for valid passages.
        for(int i = 0; i < candidates.size; i++) {
            int doc = candidates.docs[i];

            //
            // Get the positions for the terms in this document.
            for(int j = 0; j < terms.size(); j++) {
                if(terms.get(j) != null) {
                    fieldPosns[j] = ((DictTerm) terms.get(j)).getPositions(doc);
                }
            }

            //
            // For each of the fields that we're supposed to do, collect up
            // the positions into our columns array.
            boolean somePassage = false;
            for(int f = 0; f < doFields.length; f++) {

                if(doFields[f] == 0) {
                    continue;
                }

                //
                // Zero out the column lengths.
                for(int j = 0; j < lens.length; j++) {
                    lens[j] = 0;
                }

                for(int j = 0; j < fieldPosns.length; j++) {

                    if(fieldPosns[j] == null) {
                        continue;
                    }

                    //
                    // Get the positions for this field for this term.
                    int[] fposns = fieldPosns[j][f];
                    int nPosns = fposns[0];

                    //
                    // No positions, so keep going.
                    if(nPosns == 0) {
                        continue;
                    }

                    //
                    // The current column and its length.
                    if(nPosns + lens[j] >= columns[j].length) {
                        columns[j] = Arrays.copyOf(columns[j],
                                                    (nPosns + lens[j]) * 2);
                    }

                    System.arraycopy(fposns, 1, columns[j], lens[j], nPosns);
                    lens[j] += nPosns;

                    if(lens[j] > columns[j].length) {
                        logger.info("lens exceeds column length");
                        logger.info("part: " + part);
                        logger.info("doc: " + doc);
                        logger.info("key: " + part.getDocumentDictionary().getByID(doc));
                        logger.info("j: " + j);
                        logger.info("columns[j].length: " + columns[j].length);
                        logger.info("lens[j]: " + lens[j]);
                    }
                }

                //
                // We'll quickly check here to see how many columns are
                // empty.  If this exceeds the maximum number of missing
                // terms, we can simply move onto the next field.
                int nMissing = 0;
                for(int j = 0; j < lens.length; j++) {
                    if(lens[j] == 0) {
                        nMissing++;
                    }
                }

                if(nMissing > maxMissing) {
                    //
                    // Oops, too many missing terms!
                    continue;
                }

                //
                // Sort the positions, so that we can do our work.
                for(int j = 0; j < columns.length; j++) {
                    if(lens[j] > columns[j].length) {
                        logger.info("doc: " + doc);
                        logger.info("key: " + part.getDocumentDictionary().getByID(doc));
                        logger.info(j + " " + part + " " + lens[j] + " "
                                + columns[j].length);

                    }
                    Arrays.sort(columns[j], 0, lens[j]);
                }

                //
                // OK, now we have all the positions for our current field,
                // let's see if any of them have matching passages.  Note
                // that we don't have any intrinsic term penalties for now.
                float minPenalty =
                        checkPositions(ret, doc, f, columns, lens, ocTerms, null);

                //
                // If we actually got a passage, it will have been stored
                // in checkPositions.  We'll deal with keeping the best
                // document score here.
                if(minPenalty < Float.MAX_VALUE) {
                    somePassage = true;
                    float score = (100 - minPenalty) / 100;

                    if(score > ret.scores[ret.size]) {
                        ret.scores[ret.size] = score;
                    }
                }
            }

            //
            // If we found some passages, we need to put the document in
            // the return set and move onto the next element in the return
            // set.
            if(somePassage) {
                ret.docs[ret.size] = doc;

                //
                // If we're supposed to boost perfect scores, do it now.
                if(qc.getBoostPerfectProx() && ret.scores[ret.size] == 1) {
                    ret.scores[ret.size] += scoredCandidates.scores[i];
                    nPerfect++;
                    if(ret.scores[ret.size] > maxScore) {
                        maxScore = ret.scores[ret.size];
                    }
                }
                ret.size++;
            }
        }

        //
        // See if we need to normalize down scores greater than 1.
        if(maxScore > 1) {
            for(int i = 0; i < ret.size; i++) {
                if(ret.scores[i] > 1) {
                    ret.scores[i] /= maxScore;
                }
            }
        }
        ret.sqw = 1;
        ret.normalized = true;

        return ret;
    }

    /**
     * Calculates the penalty produced by a set of positions from a
     * document.  This penalty includes any gap or out-of-order penalty.
     * Inherent term penalties should be calculated separately and added to
     * the return value of this method.
     *
     * @param posns The set of positions for which we wish to calculate the
     * penalty.  Missing terms may be indicated by values less than zero.
     * @return The penalty associated with the given word positions.
     */
    protected float calcPenalty(int[] posns) {
        float penalty = 0;
        int pos, diff;
        int prev = posns[0];

        for(int i = 1; i < posns.length; i++) {
            pos = posns[i];

            //
            // Skip missing terms.
            if(pos < 0) {
                continue;
            }

            //
            // Figure out any gap or out of order penalty.
            if(prev > 0) {
                diff = pos - prev;

                if(diff < 0) {

                    //
                    // Out of order penalty.
                    penalty += (gapPenalty * -diff) + oooPenalty;
                } else if(diff > 1) {

                    //
                    // Gap penalty.
                    penalty += gapPenalty * (diff - 1);
                }
            }
            prev = pos;
        }

        return penalty;
    }

    /**
     * Finds qualifying passages in the given positions.
     *
     * @param ag The <code>ScoredGroup</code> where we'll add our passages.
     * @param field The ID of the field that we're currently processing.
     * @param columns The word positions for each column, in order.
     * @param lens The lengths of the columns.
     * @param ocColumn If the <em>i<sup>th</sup></em> element is
     * <code>true</code> then the <em>i<sup>th</sup></em> column was
     * generated by a <code>onchar</code> operator.
     * @param termPens The penalties inherent in the terms.
     * <code>Float.MIN_VALUE</code> is returned.
     */
    protected float checkPositions(ScoredGroup ag,
                                   int doc,
                                   int field,
                                   int[][] columns,
                                   int[] lens,
                                   boolean[] ocColumn,
                                   float[][] termPens) {

        int minCol = -1;
        int minPos;
        int maxPos = Integer.MIN_VALUE;
        int nMissing;
        float penalty;
        int[] currPos = new int[columns.length];
        int[] tops = new int[columns.length];
        float[] topTermPens = new float[columns.length];
        float minPenalty = Float.MAX_VALUE;
        boolean addedPassages = false;
        
        //
        // Fill the columns for the first go-round.
        int prevTop = -1;
        for(int i = 0; i < columns.length; i++) {
            tops[i] = -1;
            if(!ocColumn[i]) {
                if(lens[i] > 0) {
                    tops[i] = columns[i][0];
                }
                if(tops[i] > maxPos) {
                    maxPos = tops[i];
                }
            } else {
                tops[i] = prevTop > 0 ? prevTop + 1 : prevTop;
            }
            prevTop = tops[i];
        }

        //
        // We'll walk through the positions data until the columns are
        // exhausted, or until we can't add any more hits.
        colLoop:
        while(true) {

            //
            // Just replace the top element that we removed the last time
            // around.
            if(minCol != -1) {
                int pos = currPos[minCol];
                if(pos < lens[minCol]) {
                    int newPos = columns[minCol][pos];
                    tops[minCol] = newPos;
                    topTermPens[minCol] =
                            termPens == null ? 0 : termPens[minCol][pos];
                    int nc = minCol + 1;
                    if(nc < ocColumn.length && ocColumn[nc]) {
                        tops[nc] = newPos + 1;
                    }
                    if(newPos > maxPos) {
                        maxPos = newPos;
                    }
                } else {
                    tops[minCol] = -1;
                }
            }

            nMissing = 0;
            penalty = 0;
            minCol = 0;
            minPos = Integer.MAX_VALUE;
            prevTop = -1;

            //
            // Find the minimum column in the new tops and calculate the
            // number of missing terms and the associated penalties.
            for(int i = 0; i < tops.length; i++) {

                int currTop = tops[i];

                if(currTop > 0) {
                    if(currTop < minPos) {
                        minCol = i;
                        minPos = currTop;
                    }
                    penalty += topTermPens[i];
                } else {
                    nMissing++;

                    //
                    // SJG:  fix for variable missing term penalty,
                    // especially for high frequency terms.
                    penalty += 10;
                }

                prevTop = currTop;
            }

            //
            // Can we stop?  We can stop if we have exceeded the max number
            // of missing columns.
            if(nMissing > maxMissing || nMissing == columns.length) {
                break;
            }

            //
            // If the width of the passage exceeds our window size, then we
            // should just go on to the next one.
            int cover = maxPos - minPos;
            if(cover > maxWindow || cover < minWindow) {
                currPos[minCol]++;
                continue colLoop;
            }

            //
            // If we're supposed to have the terms in order and they're
            // not, we can go on.
            if(inOrder) {
                for(int i = 0; i < tops.length; i++) {
                    int pos = tops[i];
                    if(pos < 0) {
                        continue;
                    }
                    for(int j = i + 1; j < tops.length; j++) {
                        int pos2 = tops[j];
                        if(pos2 < 0) {
                            continue;
                        }
                        if(pos > pos2) {
                            //
                            // We have an out-of-order column go onto the
                            // next set of positions.
                            currPos[minCol]++;
                            continue colLoop;
                        } else if(pos == pos2) {

                            //
                            // We have an equal column.  Discard the later
                            // column and continue.
                            minCol = j;
                            currPos[j]++;
                            continue colLoop;
                        }
                    }
                }
            } else {

                //
                // Check for equal columns.
                for(int i = 0; i < tops.length; i++) {
                    int pos = tops[i];
                    if(pos < 0) {
                        continue;
                    }
                    for(int j = i + 1; j < tops.length; j++) {
                        int pos2 = tops[j];
                        if(pos2 < 0) {
                            continue;
                        }

                        if(pos == pos2) {

                            //
                            // We have an equal column.  If one of the
                            // columns is from a one-char, we should
                            // discard the column that is not a one-char.
                            // If neither of the columns is a one-char,
                            // remove the later of the two.  Both being
                            // onechars should never happen, because that
                            // would imply that the previous columns would
                            // be equal and that would be caught by one of
                            // the cases above.  But just in that case, we
                            // just increment the minimum column and
                            // continue.
                            boolean oc1 = ocColumn[i];
                            boolean oc2 = ocColumn[j];
                            if(oc1 && oc2) {
                                if(!oc2) {
                                    minCol = j;
                                    currPos[j]++;
                                } else {
                                    currPos[minCol]++;
                                }
                            } else {
                                if(oc2) {
                                    minCol = i;
                                    currPos[i]++;
                                } else {
                                    minCol = j;
                                    currPos[j]++;
                                }
                            }
                            continue colLoop;
                        }
                    }
                }
            }

            //
            // Now we can check for a new hit.
            penalty += calcPenalty(tops);

            //
            // Penalties that >= 100 indicate seriously flawed passages
            // that we will simply ignore.
            if(penalty >= 100) {
                currPos[minCol]++;
                continue colLoop;
            }

            //
            // Keep track of the minimum penalty.
            if(penalty < minPenalty) {

                minPenalty = penalty;

                //
                // Save this passage, if required.
                if(storePassages) {
                    ag.addPassage(field, tops, penalty);
                }
                addedPassages = true;
            }


            //
            // If we find a hit with 0 penalty, and we're not supposed to
            // keep our positions around, we may as well call it a day,
            // since we can't find a better hit.
            if(penalty == 0 && !storePassages) {
                break colLoop;
            }

            //
            // Remove the smallest position.
            currPos[minCol]++;
        }

        return minPenalty;
    }

    protected static String printCols(int[][] columns, int[] lens) {
        StringBuilder b = new StringBuilder();
        int maxLen = 0;
        for(int i = 0; i < lens.length; i++) {
            if(lens[i] > maxLen) {
                maxLen = lens[i];
            }
        }
        for(int i = 0; i < maxLen; i++) {
            for(int j = 0; j < columns.length; j++) {
                if(i < lens[j]) {
                    b.append("  ").append(columns[j][i]);
                } else {
                    b.append("  -1");
                }
            }
            b.append('\n');
        }
        return b.toString();
    }

    protected void arrayCopy(int[] src, int srcPos, int[] dst, int dstPos,
                             int len) {
        for(int i = 0; i < len; i++) {
            dst[dstPos++] = src[srcPos++];
        }
    }
} // Proximity

